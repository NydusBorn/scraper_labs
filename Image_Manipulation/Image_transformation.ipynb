{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOkhij9Xi1MI"
   },
   "source": [
    "# Трасформация изображений\n",
    "\n",
    "В этом уроке мы рассмотрим основные операции преобразования изображений в OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb_3w39Hi1ML"
   },
   "source": [
    "## 1. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "r6UaunjEi1ML",
    "outputId": "82f4eedb-7351-4e7e-e34e-a77f2b0cf949"
   },
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('IU.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "print(f\"Original shape: {img.shape}\")\n",
    "plt.imshow(img)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "7BXM3EqHi1MM",
    "outputId": "3b6d0ef1-4f98-4467-952b-837a4c112da8"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)\n",
    "# OR\n",
    "height, width = img.shape[:2]\n",
    "res = cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_LINEAR)\n",
    "print(f\"Resized shape: {res.shape}\")\n",
    "plt.imshow(res)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "LvW5M7cQi1MM",
    "outputId": "0891aedf-de82-46bb-8e46-883b8f81d69d"
   },
   "source": [
    "res_down = cv.resize(img,None,fx=0.3, fy=0.3, interpolation = cv.INTER_AREA)\n",
    "print(f\"Resized shape: {res_down.shape}\")\n",
    "plt.imshow(res_down)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCpWD_JEi1MN"
   },
   "source": [
    "Сравним с кубическим методом интерполяции:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "5vVDohbGi1MN",
    "outputId": "3693a99e-8fc3-4fc3-94db-fe494d07352f"
   },
   "source": [
    "res_down = cv.resize(img,None,fx=0.3, fy=0.3, interpolation = cv.INTER_CUBIC)\n",
    "plt.imshow(res_down)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yXkte5Ri1MN"
   },
   "source": [
    "Предпочтительной интерполяцией для сжатия является INTER_AREA, для расширения - INTER_LINEAR или INTER_CUBIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ79ZhZbi1MN"
   },
   "source": [
    "\n",
    "**INTER_AREA**: INTER_AREA uses pixel area relation for resampling. This is best suited for reducing the size of an image (shrinking). When used for zooming into the image, it uses the INTER_NEAREST method.\n",
    "\n",
    "**INTER_CUBIC**: This uses bicubic interpolation for resizing the image. While resizing and interpolating new pixels, this method acts on the 4×4 neighboring pixels of the image. It then takes the weights average of the 16 pixels to create the new interpolated pixel.\n",
    "\n",
    "**INTER_LINEAR**: This method is somewhat similar to the INTER_CUBIC interpolation. But unlike INTER_CUBIC, this uses 2×2 neighboring pixels to get the weighted average for the interpolated pixel.\n",
    "\n",
    "**INTER_NEAREST**: The INTER_NEAREST method uses the nearest neighbor concept for interpolation. This is one of the simplest methods, using only one neighboring pixel from the image for interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emmov3_7i1MN"
   },
   "source": [
    "## 2. Translation\n",
    "\n",
    "Мы говорили о том, что через аффинное преобразование можно выразить scaling, translation, rotation, и их комбинации. В OpenCV это реализуется через функцию `warpAffine`, которая принимает входное изображение (можно цветное), матрицу трансформации и выходной размер картинки"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "wQUGqFHPi1MN",
    "outputId": "4d61c574-3624-41b6-a1d0-27c4e0e0a1a9"
   },
   "source": [
    "rows, cols, _ = img.shape\n",
    "\n",
    "# Создаем матрицу переноса\n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "plt.imshow(dst)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1X2fAaKi1MN"
   },
   "source": [
    "## 3. Rotation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "akwdi_aZi1MO",
    "outputId": "9cca338e-5e8c-40a1-9a3b-14faae18e15d"
   },
   "source": [
    "rows,cols, _ = img.shape\n",
    "\n",
    "# Поворот вокруг центра изображения\n",
    "alpha = 45\n",
    "scale = 1\n",
    "center = ((cols-1)/2.0,(rows-1)/2.0)\n",
    "M = cv.getRotationMatrix2D(center,alpha,scale)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "plt.imshow(dst)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsUX7QNni1MO"
   },
   "source": [
    "## 4. Affine transformation\n",
    "\n",
    "Аффинное преобразование в общем случае ожидает 3 координаты на входном и выходном изображениях. По пропорциям между ними будет преобразованно все изображение"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "xyreKFHLi1MO",
    "outputId": "f3c3b007-0b70-4e76-9426-5df44faa678c"
   },
   "source": [
    "pts1 = np.float32([[455,180],[450,100],[230,180]])\n",
    "pts2 = np.float32([[500,100],[400,50],[100,300]])\n",
    "plt.imshow(img)\n",
    "plt.plot(455, 180, \"og\", markersize=5, color=\"red\")\n",
    "plt.plot(450, 100, \"og\", markersize=5, color=\"red\")\n",
    "plt.plot(230, 180, \"og\", markersize=5, color=\"red\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "RxWDb1h4i1MO",
    "outputId": "d821ee4e-6c49-4dfb-97f3-ab0b7b5322b1"
   },
   "source": [
    "M = cv.getAffineTransform(pts1,pts2)\n",
    "# Убедимся, что M перемещает pts1[0] в pts2[0]\n",
    "print(np.array(M))\n",
    "print(np.array(pts1[0]).T)\n",
    "print(np.array(M).dot(np.array([[*pts1[0], 1]]).T).T)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "plt.imshow(dst)\n",
    "\n",
    "plt.plot(500, 100, \"x\", markersize=7, color=\"red\")\n",
    "plt.plot(400, 50, \"x\", markersize=7, color=\"red\")\n",
    "plt.plot(100, 300, \"x\", markersize=7, color=\"red\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53tlv-jqi1MO"
   },
   "source": [
    "Scaling через affine transformation:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "5Mezk5P2i1MO",
    "outputId": "14182fde-b0a7-42eb-ce2a-d5be4c664ab4"
   },
   "source": [
    "alpha = 2\n",
    "beta = 2\n",
    "pts1 = np.float32([[455,180],[450,100],[230,180]])\n",
    "pts2 = np.float32([[455*alpha,180*beta],[450*alpha,100*beta],[230*alpha,180*beta]])\n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    "rows, cols, _ = img.shape\n",
    "dst = cv.warpAffine(img,M,(cols*alpha,rows*beta), cv.INTER_LINEAR)\n",
    "plt.imshow(dst)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi1oOvpai1MO"
   },
   "source": [
    "## 5. Perspective transformation\n",
    "\n",
    "getPerspectiveTransform ожидает 4 точки из изображений"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "_edJ1G0Ji1MO",
    "outputId": "b243953e-c64b-4b27-d5cf-677438c154d6"
   },
   "source": [
    "img = cv.imread('sudoku.jpg')\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[56,65],[28,287],[389,390], [368,52],])\n",
    "# Cтавим на углы нового изображения\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    "# Та же операция, что и getPerspectiveTransform\n",
    "print(cv.findHomography(pts1, pts2)[0])\n",
    "print(M)\n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    "plt.figure(figsize=(12, 12), dpi=80)\n",
    "plt.subplot(131),plt.imshow(img),plt.title('Input')\n",
    "plt.plot(56, 65, \"x\", markersize=5, color=\"red\")\n",
    "plt.plot(368, 52, \"x\", markersize=5, color=\"red\")\n",
    "plt.plot(28, 287, \"x\", markersize=5, color=\"red\")\n",
    "plt.plot(389, 390, \"x\", markersize=5, color=\"red\")\n",
    "\n",
    "\n",
    "plt.subplot(132),plt.imshow(dst),plt.title('Perspective')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
